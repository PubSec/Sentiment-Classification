{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating                                             review\n",
       "0  negative  terrible place to work for i just heard a stor...\n",
       "1  negative   hours , minutes total time for an extremely s...\n",
       "2  negative  my less than stellar review is for service . w...\n",
       "3  negative  i m granting one star because there s no way t...\n",
       "4  negative  the food here is mediocre at best . i went aft..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.set()\n",
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55995</th>\n",
       "      <td>positive</td>\n",
       "      <td>great food . wonderful , friendly service . i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>positive</td>\n",
       "      <td>charlotte should be the new standard for moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>positive</td>\n",
       "      <td>get the encore sandwich ! ! make sure to get i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>positive</td>\n",
       "      <td>i m a pretty big ice cream gelato fan . pretty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>positive</td>\n",
       "      <td>where else can you find all the parts and piec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review\n",
       "55995  positive  great food . wonderful , friendly service . i ...\n",
       "55996  positive  charlotte should be the new standard for moder...\n",
       "55997  positive  get the encore sandwich ! ! make sure to get i...\n",
       "55998  positive  i m a pretty big ice cream gelato fan . pretty...\n",
       "55999  positive  where else can you find all the parts and piec..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "def initialise_vocabulary():\n",
    "    unknown_token = \"<UNK>\"\n",
    "    vocab['t_2_i'] = {}\n",
    "    vocab['i_2_t'] = {}\n",
    "    vocab['unknownToken'] = unknown_token\n",
    "    idx = add_token(unknown_token)\n",
    "    vocab['unknownTokenIdx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(token)-> int:\n",
    "    if token in vocab['t_2_i']:\n",
    "        idx = vocab['t_2_i'][token]\n",
    "    else:\n",
    "        idx = len(vocab['t_2_i'])\n",
    "        vocab['t_2_i'][token] = idx\n",
    "        vocab['i_2_t'][idx] = token\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_many_token(tokens)-> list:\n",
    "    idxes = [add_token(token) for token in tokens]\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_token(token)-> int:\n",
    "    if vocab['unknownTokenIdx'] >= 0:\n",
    "        return vocab['t_2_i'].get(token,vocab['unknownTokenIdx'])\n",
    "    else:\n",
    "        return vocab['t_2_i'][token] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_index(idx):\n",
    "    if idx not in vocab['i_2_t']:\n",
    "        raise KeyError(\"The index (%d) is not there\" %idx)\n",
    "    return vocab['i_2_t'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "/tmp/ipykernel_13105/3335798830.py:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  for word in re.split('\\W+',r):\n"
     ]
    }
   ],
   "source": [
    "def vocabulary_from_data_frame(df, cutoff=25):\n",
    "    initialise_vocabulary()\n",
    "    word_counts = Counter()\n",
    "    for r in df.review:\n",
    "        for word in re.split('\\W+',r):\n",
    "            word_counts[word] += 1\n",
    "\n",
    "    for word,count in word_counts.items():\n",
    "        if count > cutoff:\n",
    "            add_token(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "/tmp/ipykernel_13105/3454605035.py:5: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  for word in re.split('\\W+',doc):\n"
     ]
    }
   ],
   "source": [
    "def vocabulary_from_corpus(Corpus, cutoff=25):\n",
    "    initialise_vocabulary()\n",
    "    word_counts = Counter()\n",
    "    for doc in Corpus:\n",
    "        for word in re.split('\\W+',doc):\n",
    "            word_counts[word] += 1\n",
    "\n",
    "    for word,count in word_counts.items():\n",
    "        if count > cutoff:\n",
    "            add_token(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary_from_data_frame(df)\n",
    "Corpus = np.asarray(df['review'])\n",
    "vocabulary_from_corpus(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "215\n",
      "8946\n",
      "8946\n"
     ]
    }
   ],
   "source": [
    "print(look_up_token('the'))\n",
    "print(look_up_token('book'))\n",
    "print(len(vocab['t_2_i']))\n",
    "print(len(vocab['i_2_t']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<UNK>',\n",
       " 1: 'terrible',\n",
       " 2: 'place',\n",
       " 3: 'to',\n",
       " 4: 'work',\n",
       " 5: 'for',\n",
       " 6: 'i',\n",
       " 7: 'just',\n",
       " 8: 'heard',\n",
       " 9: 'a',\n",
       " 10: 'story',\n",
       " 11: 'of',\n",
       " 12: 'them',\n",
       " 13: 'find',\n",
       " 14: 'girl',\n",
       " 15: 'over',\n",
       " 16: 'her',\n",
       " 17: 'father',\n",
       " 18: 'coming',\n",
       " 19: 'in',\n",
       " 20: 'there',\n",
       " 21: 'who',\n",
       " 22: 'she',\n",
       " 23: 'hadn',\n",
       " 24: 't',\n",
       " 25: 'seen',\n",
       " 26: 'years',\n",
       " 27: 'said',\n",
       " 28: 'hi',\n",
       " 29: 'him',\n",
       " 30: 'which',\n",
       " 31: 'upset',\n",
       " 32: 'his',\n",
       " 33: 'wife',\n",
       " 34: 'and',\n",
       " 35: 'they',\n",
       " 36: 'left',\n",
       " 37: 'finished',\n",
       " 38: 'the',\n",
       " 39: 'rest',\n",
       " 40: 'day',\n",
       " 41: 'working',\n",
       " 42: 'fine',\n",
       " 43: 'next',\n",
       " 44: 'when',\n",
       " 45: 'went',\n",
       " 46: 'into',\n",
       " 47: 'fired',\n",
       " 48: 'that',\n",
       " 49: 'situation',\n",
       " 50: 'one',\n",
       " 51: 'texas',\n",
       " 52: 'roadhouse',\n",
       " 53: 'because',\n",
       " 54: 'any',\n",
       " 55: 'could',\n",
       " 56: 'be',\n",
       " 57: 'their',\n",
       " 58: 'staff',\n",
       " 59: 'does',\n",
       " 60: 'not',\n",
       " 61: 'deserve',\n",
       " 62: 'my',\n",
       " 63: 'business',\n",
       " 64: 'yelp',\n",
       " 65: 'wants',\n",
       " 66: 'me',\n",
       " 67: 'give',\n",
       " 68: 'star',\n",
       " 69: 'but',\n",
       " 70: 'don',\n",
       " 71: 'believe',\n",
       " 72: 'it',\n",
       " 73: '',\n",
       " 74: 'hours',\n",
       " 75: 'minutes',\n",
       " 76: 'total',\n",
       " 77: 'time',\n",
       " 78: 'an',\n",
       " 79: 'extremely',\n",
       " 80: 'simple',\n",
       " 81: 'physical',\n",
       " 82: 'stay',\n",
       " 83: 'away',\n",
       " 84: 'unless',\n",
       " 85: 'you',\n",
       " 86: 'have',\n",
       " 87: 'waste',\n",
       " 88: 'less',\n",
       " 89: 'than',\n",
       " 90: 'stellar',\n",
       " 91: 'review',\n",
       " 92: 'is',\n",
       " 93: 'service',\n",
       " 94: 'we',\n",
       " 95: 'waited',\n",
       " 96: 'our',\n",
       " 97: 'meals',\n",
       " 98: 'delivered',\n",
       " 99: 'questioned',\n",
       " 100: 'waiter',\n",
       " 101: 'he',\n",
       " 102: 'was',\n",
       " 103: 'helpful',\n",
       " 104: 'so',\n",
       " 105: 'asked',\n",
       " 106: 'speak',\n",
       " 107: 'manager',\n",
       " 108: 'did',\n",
       " 109: 'even',\n",
       " 110: 'come',\n",
       " 111: 'with',\n",
       " 112: 'us',\n",
       " 113: 'were',\n",
       " 114: 'loyal',\n",
       " 115: 'neighborhood',\n",
       " 116: 'customers',\n",
       " 117: 'walking',\n",
       " 118: 'restaurant',\n",
       " 119: 'frequently',\n",
       " 120: 'husband',\n",
       " 121: 'then',\n",
       " 122: 'wrote',\n",
       " 123: 'email',\n",
       " 124: 'owner',\n",
       " 125: 'ignored',\n",
       " 126: 'by',\n",
       " 127: 'as',\n",
       " 128: 'well',\n",
       " 129: 'this',\n",
       " 130: 'obviously',\n",
       " 131: 'value',\n",
       " 132: 'customer',\n",
       " 133: 'very',\n",
       " 134: 'disappointed',\n",
       " 135: 'has',\n",
       " 136: 'lost',\n",
       " 137: 'regular',\n",
       " 138: 'm',\n",
       " 139: 's',\n",
       " 140: 'no',\n",
       " 141: 'way',\n",
       " 142: 'none',\n",
       " 143: 'n',\n",
       " 144: 'nas',\n",
       " 145: 'write',\n",
       " 146: 'door',\n",
       " 147: 'room',\n",
       " 148: 'open',\n",
       " 149: 'two',\n",
       " 150: 'gentlemen',\n",
       " 151: 'are',\n",
       " 152: 'checked',\n",
       " 153: 'going',\n",
       " 154: 'go',\n",
       " 155: 'on',\n",
       " 156: 'all',\n",
       " 157: 'evidently',\n",
       " 158: 'inn',\n",
       " 159: 'new',\n",
       " 160: 'lock',\n",
       " 161: 'system',\n",
       " 162: 'some',\n",
       " 163: 'reason',\n",
       " 164: 'impossible',\n",
       " 165: 'wait',\n",
       " 166: 'until',\n",
       " 167: 'out',\n",
       " 168: 'later',\n",
       " 169: 'today',\n",
       " 170: 'counting',\n",
       " 171: 'quiet',\n",
       " 172: 'd',\n",
       " 173: 'brought',\n",
       " 174: 'do',\n",
       " 175: 'now',\n",
       " 176: 'utterly',\n",
       " 177: 'stayed',\n",
       " 178: 'here',\n",
       " 179: 'once',\n",
       " 180: 'before',\n",
       " 181: 'loved',\n",
       " 182: 'lack',\n",
       " 183: 'concern',\n",
       " 184: 'respect',\n",
       " 185: 'sets',\n",
       " 186: 'low',\n",
       " 187: 'food',\n",
       " 188: 'mediocre',\n",
       " 189: 'at',\n",
       " 190: 'best',\n",
       " 191: 'after',\n",
       " 192: 'reading',\n",
       " 193: 'above',\n",
       " 194: 'positive',\n",
       " 195: 'reviews',\n",
       " 196: 'really',\n",
       " 197: 'great',\n",
       " 198: 'hence',\n",
       " 199: 'stars',\n",
       " 200: 'relleno',\n",
       " 201: 'soggy',\n",
       " 202: 'looked',\n",
       " 203: 'tasted',\n",
       " 204: 'like',\n",
       " 205: 'made',\n",
       " 206: 'factory',\n",
       " 207: 'guacamole',\n",
       " 208: 'decent',\n",
       " 209: 'didn',\n",
       " 210: 'care',\n",
       " 211: 'margarita',\n",
       " 212: 'mix',\n",
       " 213: 'nwe',\n",
       " 214: 'entertainment',\n",
       " 215: 'book',\n",
       " 216: 'pizza',\n",
       " 217: 'coupons',\n",
       " 218: 'came',\n",
       " 219: 'across',\n",
       " 220: 'domino',\n",
       " 221: 'twist',\n",
       " 222: 'fate',\n",
       " 223: 'since',\n",
       " 224: 'had',\n",
       " 225: 'easily',\n",
       " 226: 'pretty',\n",
       " 227: 'good',\n",
       " 228: 'coupon',\n",
       " 229: 'decided',\n",
       " 230: 'what',\n",
       " 231: 'seemed',\n",
       " 232: 'judgement',\n",
       " 233: 'would',\n",
       " 234: 'use',\n",
       " 235: 'shot',\n",
       " 236: 'nit',\n",
       " 237: 'will',\n",
       " 238: 'likely',\n",
       " 239: 'least',\n",
       " 240: 'try',\n",
       " 241: 'again',\n",
       " 242: 'npizza',\n",
       " 243: 'par',\n",
       " 244: 'those',\n",
       " 245: 'frozen',\n",
       " 246: 'ones',\n",
       " 247: 'from',\n",
       " 248: 'grocery',\n",
       " 249: 'store',\n",
       " 250: 'free',\n",
       " 251: 'sandwich',\n",
       " 252: 'shared',\n",
       " 253: 'tummy',\n",
       " 254: 'ndespite',\n",
       " 255: 'savings',\n",
       " 256: 'deal',\n",
       " 257: 'poor',\n",
       " 258: 'quality',\n",
       " 259: 'appointment',\n",
       " 260: 'months',\n",
       " 261: 'advance',\n",
       " 262: 'turned',\n",
       " 263: 'up',\n",
       " 264: 'told',\n",
       " 265: 'person',\n",
       " 266: 'quit',\n",
       " 267: 'weeks',\n",
       " 268: 'ago',\n",
       " 269: 'anyone',\n",
       " 270: 'available',\n",
       " 271: 'take',\n",
       " 272: 'attempt',\n",
       " 273: 'reschedule',\n",
       " 274: 'someone',\n",
       " 275: 'else',\n",
       " 276: 'or',\n",
       " 277: 'call',\n",
       " 278: 'cancel',\n",
       " 279: 'make',\n",
       " 280: 'things',\n",
       " 281: 'worse',\n",
       " 282: 'front',\n",
       " 283: 'desk',\n",
       " 284: 'such',\n",
       " 285: 'attitude',\n",
       " 286: 'tip',\n",
       " 287: 'beauty',\n",
       " 288: 'salon',\n",
       " 289: 'looks',\n",
       " 290: 'actually',\n",
       " 291: 'been',\n",
       " 292: 'rude',\n",
       " 293: 'women',\n",
       " 294: 'never',\n",
       " 295: 'back',\n",
       " 296: 'frankly',\n",
       " 297: 'get',\n",
       " 298: 'why',\n",
       " 299: 'people',\n",
       " 300: 'exception',\n",
       " 301: 'desert',\n",
       " 302: 'fruit',\n",
       " 303: 'cake',\n",
       " 304: 'dipped',\n",
       " 305: 'chocolate',\n",
       " 306: 'ok',\n",
       " 307: 'its',\n",
       " 308: 'alone',\n",
       " 309: 'nbut',\n",
       " 310: 'dinner',\n",
       " 311: 'overpriced',\n",
       " 312: 'overrated',\n",
       " 313: 'family',\n",
       " 314: 'friendly',\n",
       " 315: 'much',\n",
       " 316: 'better',\n",
       " 317: 'options',\n",
       " 318: 'terms',\n",
       " 319: 'thought',\n",
       " 320: 'nd',\n",
       " 321: 'chance',\n",
       " 322: 'bad',\n",
       " 323: 'idea',\n",
       " 324: 'employees',\n",
       " 325: 'feel',\n",
       " 326: 'your',\n",
       " 327: 'putting',\n",
       " 328: 'ordering',\n",
       " 329: 'if',\n",
       " 330: 'owners',\n",
       " 331: 'change',\n",
       " 332: 'quickly',\n",
       " 333: 'negative',\n",
       " 334: 'fried',\n",
       " 335: 'wontons',\n",
       " 336: 'stale',\n",
       " 337: 'awful',\n",
       " 338: 'kung',\n",
       " 339: 'pao',\n",
       " 340: 'chicken',\n",
       " 341: 'dry',\n",
       " 342: 'worth',\n",
       " 343: 'eating',\n",
       " 344: 'sun',\n",
       " 345: 'devil',\n",
       " 346: 'pork',\n",
       " 347: 'stringy',\n",
       " 348: 'filled',\n",
       " 349: 'gristle',\n",
       " 350: 'eat',\n",
       " 351: 'waitress',\n",
       " 352: 'how',\n",
       " 353: 'nothing',\n",
       " 354: 'b',\n",
       " 355: 'g',\n",
       " 356: 'refused',\n",
       " 357: 'yourself',\n",
       " 358: 'favor',\n",
       " 359: 'agree',\n",
       " 360: 'similar',\n",
       " 361: 'off',\n",
       " 362: 'bell',\n",
       " 363: 'mess',\n",
       " 364: 'stuff',\n",
       " 365: 'consignment',\n",
       " 366: 'credit',\n",
       " 367: 'return',\n",
       " 368: 'taken',\n",
       " 369: 'item',\n",
       " 370: 'big',\n",
       " 371: 'bags',\n",
       " 372: 'hardly',\n",
       " 373: 'used',\n",
       " 374: 'brand',\n",
       " 375: 'baby',\n",
       " 376: 'clothes',\n",
       " 377: 'ni',\n",
       " 378: 'bought',\n",
       " 379: 'several',\n",
       " 380: 'particular',\n",
       " 381: 'looking',\n",
       " 382: 'shoes',\n",
       " 383: 'filthy',\n",
       " 384: 'smell',\n",
       " 385: 'horrible',\n",
       " 386: 'toys',\n",
       " 387: 'missing',\n",
       " 388: 'parts',\n",
       " 389: 'grungy',\n",
       " 390: 'yet',\n",
       " 391: 'still',\n",
       " 392: 'greenway',\n",
       " 393: 'also',\n",
       " 394: 'witnessed',\n",
       " 395: 'area',\n",
       " 396: 'trash',\n",
       " 397: 'talking',\n",
       " 398: 'earlier',\n",
       " 399: 'conversation',\n",
       " 400: 'love',\n",
       " 401: 'shops',\n",
       " 402: 'kids',\n",
       " 403: 'mom',\n",
       " 404: 'learn',\n",
       " 405: 'buck',\n",
       " 406: 'stretch',\n",
       " 407: 'suggest',\n",
       " 408: 'upon',\n",
       " 409: 'child',\n",
       " 410: 'litchfield',\n",
       " 411: 'other',\n",
       " 412: 'mothers',\n",
       " 413: 'petsmart',\n",
       " 414: 'worst',\n",
       " 415: 'dog',\n",
       " 416: 'ntheir',\n",
       " 417: 'disgusting',\n",
       " 418: 'leave',\n",
       " 419: 'steel',\n",
       " 420: 'kennel',\n",
       " 421: 'themselves',\n",
       " 422: 'pay',\n",
       " 423: 'attention',\n",
       " 424: 'pup',\n",
       " 425: 'gave',\n",
       " 426: 'wrong',\n",
       " 427: 'medicine',\n",
       " 428: 'thousands',\n",
       " 429: 'vet',\n",
       " 430: 'stomach',\n",
       " 431: 'pumped',\n",
       " 432: 'trust',\n",
       " 433: 'dogs',\n",
       " 434: 'these',\n",
       " 435: 'crap',\n",
       " 436: 'shows',\n",
       " 437: 'overcharge',\n",
       " 438: 'most',\n",
       " 439: 'private',\n",
       " 440: 'places',\n",
       " 441: 'cheaper',\n",
       " 442: 'paying',\n",
       " 443: 'name',\n",
       " 444: 'having',\n",
       " 445: 'corporation',\n",
       " 446: 'behind',\n",
       " 447: 'doggie',\n",
       " 448: 'too',\n",
       " 449: 'check',\n",
       " 450: 'toss',\n",
       " 451: 'random',\n",
       " 452: 'stranger',\n",
       " 453: 'nthe',\n",
       " 454: 'grooming',\n",
       " 455: 'many',\n",
       " 456: 'screams',\n",
       " 457: 'groomers',\n",
       " 458: 'about',\n",
       " 459: 'taking',\n",
       " 460: 'either',\n",
       " 461: 'want',\n",
       " 462: 'money',\n",
       " 463: 'top',\n",
       " 464: 'package',\n",
       " 465: 'oatmeal',\n",
       " 466: 'cough',\n",
       " 467: 'bullshit',\n",
       " 468: 'shampoo',\n",
       " 469: 'lame',\n",
       " 470: 'teeth',\n",
       " 471: 'done',\n",
       " 472: 'salons',\n",
       " 473: 'vets',\n",
       " 474: 'offer',\n",
       " 475: 'services',\n",
       " 476: 'prices',\n",
       " 477: 'know',\n",
       " 478: 'tough',\n",
       " 479: 'economy',\n",
       " 480: 'important',\n",
       " 481: 'save',\n",
       " 482: 'bucks',\n",
       " 483: 'wherever',\n",
       " 484: 'whenever',\n",
       " 485: 'can',\n",
       " 486: 'every',\n",
       " 487: 'bother',\n",
       " 488: 'bring',\n",
       " 489: 'annoying',\n",
       " 490: 'll',\n",
       " 491: 'phone',\n",
       " 492: 'products',\n",
       " 493: 'items',\n",
       " 494: 'pet',\n",
       " 495: 'supply',\n",
       " 496: 'th',\n",
       " 497: 'mcdowell',\n",
       " 498: 'half',\n",
       " 499: 're',\n",
       " 500: 'something',\n",
       " 501: 'tell',\n",
       " 502: 'getting',\n",
       " 503: 'direct',\n",
       " 504: 'pee',\n",
       " 505: 'shelves',\n",
       " 506: 'stand',\n",
       " 507: 'around',\n",
       " 508: 'ignoring',\n",
       " 509: 'banfield',\n",
       " 510: 'joke',\n",
       " 511: 'wanted',\n",
       " 512: 'charge',\n",
       " 513: 'treat',\n",
       " 514: 'cats',\n",
       " 515: 'ear',\n",
       " 516: 'infection',\n",
       " 517: 'personal',\n",
       " 518: 'whatsoever',\n",
       " 519: 'shit',\n",
       " 520: 'nbottom',\n",
       " 521: 'line',\n",
       " 522: 'somewhere',\n",
       " 523: 'hundred',\n",
       " 524: 'times',\n",
       " 525: 'more',\n",
       " 526: 'professional',\n",
       " 527: 'pain',\n",
       " 528: 'dread',\n",
       " 529: 'each',\n",
       " 530: 'trip',\n",
       " 531: 'facility',\n",
       " 532: 'beat',\n",
       " 533: 'rugs',\n",
       " 534: 'stained',\n",
       " 535: 'wear',\n",
       " 536: 'flip',\n",
       " 537: 'flops',\n",
       " 538: 'towels',\n",
       " 539: 'need',\n",
       " 540: 'start',\n",
       " 541: 'first',\n",
       " 542: 'second',\n",
       " 543: 'washers',\n",
       " 544: 'expensive',\n",
       " 545: 've',\n",
       " 546: 'found',\n",
       " 547: 'city',\n",
       " 548: 'restrooms',\n",
       " 549: 'kind',\n",
       " 550: 'sends',\n",
       " 551: 'block',\n",
       " 552: 'down',\n",
       " 553: 'street',\n",
       " 554: 'coffee',\n",
       " 555: 'shop',\n",
       " 556: 'restroom',\n",
       " 557: 'last',\n",
       " 558: 'joint',\n",
       " 559: 'ate',\n",
       " 560: 'purchased',\n",
       " 561: 'groupon',\n",
       " 562: 'both',\n",
       " 563: 'enjoy',\n",
       " 564: 'greek',\n",
       " 565: 'excited',\n",
       " 566: 'lunch',\n",
       " 567: 'while',\n",
       " 568: 'definitely',\n",
       " 569: 'ordered',\n",
       " 570: 'falafel',\n",
       " 571: 'pita',\n",
       " 572: 'wasn',\n",
       " 573: 'enough',\n",
       " 574: 'help',\n",
       " 575: 'portions',\n",
       " 576: 'huge',\n",
       " 577: 'sort',\n",
       " 578: 'thing',\n",
       " 579: 'however',\n",
       " 580: 'am',\n",
       " 581: 'eater',\n",
       " 582: 'leftovers',\n",
       " 583: 'tend',\n",
       " 584: 'fridge',\n",
       " 585: 'particularly',\n",
       " 586: 'impressed',\n",
       " 587: 'nmy',\n",
       " 588: 'parmesan',\n",
       " 589: 'basically',\n",
       " 590: 'took',\n",
       " 591: 'breast',\n",
       " 592: 'threw',\n",
       " 593: 'marinara',\n",
       " 594: 'sauce',\n",
       " 595: 'little',\n",
       " 596: 'cheese',\n",
       " 597: 'served',\n",
       " 598: 'flavor',\n",
       " 599: 'seem',\n",
       " 600: 'marinated',\n",
       " 601: 'cooked',\n",
       " 602: 'interesting',\n",
       " 603: 'ton',\n",
       " 604: 'nthis',\n",
       " 605: 'enormous',\n",
       " 606: 'alright',\n",
       " 607: 'lobby',\n",
       " 608: 'nice',\n",
       " 609: 'weird',\n",
       " 610: 'under',\n",
       " 611: 'aaa',\n",
       " 612: 'government',\n",
       " 613: 'rate',\n",
       " 614: 'main',\n",
       " 615: 'ritz',\n",
       " 616: 'number',\n",
       " 617: 'literally',\n",
       " 618: 'car',\n",
       " 619: 'hotel',\n",
       " 620: 'bar',\n",
       " 621: 'common',\n",
       " 622: 'areas',\n",
       " 623: 'guests',\n",
       " 624: 'old',\n",
       " 625: 'drinks',\n",
       " 626: 'rooms',\n",
       " 627: 'vegas',\n",
       " 628: 'maybe',\n",
       " 629: 'should',\n",
       " 630: 'diagnosed',\n",
       " 631: 'dr',\n",
       " 632: 'austin',\n",
       " 633: 'always',\n",
       " 634: 'hour',\n",
       " 635: 'keep',\n",
       " 636: 'calling',\n",
       " 637: 'office',\n",
       " 638: 'results',\n",
       " 639: 'favorite',\n",
       " 640: 'ulta',\n",
       " 641: 'locations',\n",
       " 642: 'apparently',\n",
       " 643: 'general',\n",
       " 644: 'running',\n",
       " 645: 'registers',\n",
       " 646: 'tonight',\n",
       " 647: 'sure',\n",
       " 648: 'wouldn',\n",
       " 649: 'writing',\n",
       " 650: 'sooooo',\n",
       " 651: 'say',\n",
       " 652: 'hello',\n",
       " 653: 'called',\n",
       " 654: 'register',\n",
       " 655: 'st',\n",
       " 656: 'began',\n",
       " 657: 'ring',\n",
       " 658: 'pulled',\n",
       " 659: 'ultra',\n",
       " 660: 'card',\n",
       " 661: 'needed',\n",
       " 662: 'put',\n",
       " 663: 'walked',\n",
       " 664: 'seriously',\n",
       " 665: 'might',\n",
       " 666: 'holidays',\n",
       " 667: 'helping',\n",
       " 668: 'public',\n",
       " 669: 'think',\n",
       " 670: 'drive',\n",
       " 671: 'further',\n",
       " 672: 'chandler',\n",
       " 673: 'westin',\n",
       " 674: 'chain',\n",
       " 675: 'thus',\n",
       " 676: 'expectations',\n",
       " 677: 'case',\n",
       " 678: 'met',\n",
       " 679: 'comfortable',\n",
       " 680: 'beds',\n",
       " 681: 'unfriendly',\n",
       " 682: 'appealing',\n",
       " 683: 'double',\n",
       " 684: 'shower',\n",
       " 685: 'head',\n",
       " 686: 'nnow',\n",
       " 687: 'reasons',\n",
       " 688: 'fails',\n",
       " 689: 'relatively',\n",
       " 690: 'choice',\n",
       " 691: 'examples',\n",
       " 692: 'omelet',\n",
       " 693: 'greasy',\n",
       " 694: 'tasteless',\n",
       " 695: 'canned',\n",
       " 696: 'mushrooms',\n",
       " 697: 'breakfast',\n",
       " 698: 'buffet',\n",
       " 699: 'got',\n",
       " 700: 'typically',\n",
       " 701: 'become',\n",
       " 702: 'lukewarm',\n",
       " 703: 'choices',\n",
       " 704: 'salty',\n",
       " 705: 'e',\n",
       " 706: 'salad',\n",
       " 707: 'sandwiches',\n",
       " 708: 'burgers',\n",
       " 709: 'pancakes',\n",
       " 710: 'excellent',\n",
       " 711: 'nor',\n",
       " 712: 'hyatt',\n",
       " 713: 'location',\n",
       " 714: 'omni',\n",
       " 715: 'comparable',\n",
       " 716: 'hotels',\n",
       " 717: 'restaurants',\n",
       " 718: 'shopping',\n",
       " 719: 'attractions',\n",
       " 720: 'blocks',\n",
       " 721: 'anywhere',\n",
       " 722: 'pharmacy',\n",
       " 723: 'concierge',\n",
       " 724: 'suggestion',\n",
       " 725: 'housekeeping',\n",
       " 726: 'seems',\n",
       " 727: 'only',\n",
       " 728: 'quite',\n",
       " 729: 'vacuum',\n",
       " 730: 'cracker',\n",
       " 731: 'crumbs',\n",
       " 732: 'spilled',\n",
       " 733: 'days',\n",
       " 734: 'forget',\n",
       " 735: 'essential',\n",
       " 736: 'soap',\n",
       " 737: 'nif',\n",
       " 738: 'cheap',\n",
       " 739: 'sub',\n",
       " 740: 'per',\n",
       " 741: 'night',\n",
       " 742: 'manage',\n",
       " 743: 'charlotte',\n",
       " 744: 'terribly',\n",
       " 745: 'demand',\n",
       " 746: 'spotless',\n",
       " 747: 'sexy',\n",
       " 748: 'charming',\n",
       " 749: 'neither',\n",
       " 750: 'gas',\n",
       " 751: 'high',\n",
       " 752: 'due',\n",
       " 753: 'lake',\n",
       " 754: 'proximity',\n",
       " 755: 'being',\n",
       " 756: 'station',\n",
       " 757: 'town',\n",
       " 758: 'desperate',\n",
       " 759: 'building',\n",
       " 760: 'gary',\n",
       " 761: 'anymore',\n",
       " 762: 'same',\n",
       " 763: 'dish',\n",
       " 764: 'sometimes',\n",
       " 765: 'plate',\n",
       " 766: 'depends',\n",
       " 767: 'kitchen',\n",
       " 768: 'sales',\n",
       " 769: 'listen',\n",
       " 770: 'anything',\n",
       " 771: 'printed',\n",
       " 772: 'pictures',\n",
       " 773: 'dresses',\n",
       " 774: 'styles',\n",
       " 775: 'liked',\n",
       " 776: 'dress',\n",
       " 777: 'genuinely',\n",
       " 778: 'sorry',\n",
       " 779: 'carry',\n",
       " 780: 'size',\n",
       " 781: 'overall',\n",
       " 782: 'especially',\n",
       " 783: 'won',\n",
       " 784: 'ghetto',\n",
       " 785: 'almost',\n",
       " 786: 'walmart',\n",
       " 787: 'right',\n",
       " 788: 'base',\n",
       " 789: 'long',\n",
       " 790: 'cashiers',\n",
       " 791: 'organized',\n",
       " 792: 'constantly',\n",
       " 793: 'wandering',\n",
       " 794: 'trying',\n",
       " 795: 'rather',\n",
       " 796: 'target',\n",
       " 797: 'cause',\n",
       " 798: 'ask',\n",
       " 799: 'myself',\n",
       " 800: 'edible',\n",
       " 801: 'five',\n",
       " 802: 'dollars',\n",
       " 803: 'tortilla',\n",
       " 804: 'chips',\n",
       " 805: 'homemade',\n",
       " 806: 'salsa',\n",
       " 807: 'clearly',\n",
       " 808: 'wings',\n",
       " 809: 'fake',\n",
       " 810: 'butter',\n",
       " 811: 'rubber',\n",
       " 812: 'fault',\n",
       " 813: 'guess',\n",
       " 814: 'four',\n",
       " 815: 'pad',\n",
       " 816: 'se',\n",
       " 817: 'thai',\n",
       " 818: 'stir',\n",
       " 819: 'sweet',\n",
       " 820: 'basil',\n",
       " 821: 'sides',\n",
       " 822: 'steamed',\n",
       " 823: 'sticky',\n",
       " 824: 'rice',\n",
       " 825: 'probably',\n",
       " 826: 'recommend',\n",
       " 827: 'representation',\n",
       " 828: 'heat',\n",
       " 829: 'ours',\n",
       " 830: 'level',\n",
       " 831: 'order',\n",
       " 832: 'known',\n",
       " 833: 'usually',\n",
       " 834: 'mild',\n",
       " 835: 'medium',\n",
       " 836: 'spicy',\n",
       " 837: 'hot',\n",
       " 838: 'veggies',\n",
       " 839: 'crisp',\n",
       " 840: 'noodles',\n",
       " 841: 'egg',\n",
       " 842: 'suggests',\n",
       " 843: 'means',\n",
       " 844: 'hut',\n",
       " 845: 'ever',\n",
       " 846: 'happy',\n",
       " 847: 'tried',\n",
       " 848: 'mia',\n",
       " 849: 'march',\n",
       " 850: 'mistake',\n",
       " 851: 'life',\n",
       " 852: 'crust',\n",
       " 853: 'pepperoni',\n",
       " 854: 'complain',\n",
       " 855: 'website',\n",
       " 856: 'let',\n",
       " 857: 'equipment',\n",
       " 858: 'dirty',\n",
       " 859: 'nok',\n",
       " 860: 'forgot',\n",
       " 861: 'weekend',\n",
       " 862: 'different',\n",
       " 863: 'sale',\n",
       " 864: 'nbig',\n",
       " 865: 'problems',\n",
       " 866: 'kid',\n",
       " 867: 'saw',\n",
       " 868: 'info',\n",
       " 869: 'complained',\n",
       " 870: 'nso',\n",
       " 871: 'apologized',\n",
       " 872: 'na',\n",
       " 873: 'lady',\n",
       " 874: 'nshe',\n",
       " 875: 'sound',\n",
       " 876: 'shocked',\n",
       " 877: 'pizzas',\n",
       " 878: 'using',\n",
       " 879: 'lesser',\n",
       " 880: 'ingredients',\n",
       " 881: 'nno',\n",
       " 882: 'exact',\n",
       " 883: 'words',\n",
       " 884: 'neven',\n",
       " 885: 'thanks',\n",
       " 886: 'end',\n",
       " 887: 'past',\n",
       " 888: 'sticks',\n",
       " 889: 'experiences',\n",
       " 890: 'few',\n",
       " 891: 'ruined',\n",
       " 892: 'falling',\n",
       " 893: 'zero',\n",
       " 894: 'couple',\n",
       " 895: 'tea',\n",
       " 896: 'bread',\n",
       " 897: 'barely',\n",
       " 898: 'warm',\n",
       " 899: 'squash',\n",
       " 900: 'tortellini',\n",
       " 901: 'crispy',\n",
       " 902: 'prosciutto',\n",
       " 903: 'butternut',\n",
       " 904: 'cut',\n",
       " 905: 'nanother',\n",
       " 906: 'shrimp',\n",
       " 907: 'pasta',\n",
       " 908: 'bland',\n",
       " 909: 'adding',\n",
       " 910: 'salt',\n",
       " 911: 'pepper',\n",
       " 912: 'nwill',\n",
       " 913: 'look',\n",
       " 914: 'expect',\n",
       " 915: 'whole',\n",
       " 916: 'lot',\n",
       " 917: 'albertson',\n",
       " 918: 'mega',\n",
       " 919: 'buy',\n",
       " 920: 'month',\n",
       " 921: 'became',\n",
       " 922: 'aware',\n",
       " 923: 'carried',\n",
       " 924: 'local',\n",
       " 925: 'support',\n",
       " 926: 'badly',\n",
       " 927: 'feeling',\n",
       " 928: 'playing',\n",
       " 929: 'online',\n",
       " 930: 'blue',\n",
       " 931: 'oasis',\n",
       " 932: 'surprise',\n",
       " 933: 'company',\n",
       " 934: 'las',\n",
       " 935: 'farms',\n",
       " 936: 'surprising',\n",
       " 937: 'home',\n",
       " 938: 'san',\n",
       " 939: 'francisco',\n",
       " 940: 'fresh',\n",
       " 941: 'walk',\n",
       " 942: 'nfirst',\n",
       " 943: 'doesn',\n",
       " 944: 'sell',\n",
       " 945: 'isn',\n",
       " 946: 'worker',\n",
       " 947: 'counter',\n",
       " 948: 'offered',\n",
       " 949: 'fact',\n",
       " 950: 'heads',\n",
       " 951: 'disappointing',\n",
       " 952: 'boyfriend',\n",
       " 953: 'week',\n",
       " 954: 'pound',\n",
       " 955: 'note',\n",
       " 956: 'spent',\n",
       " 957: 'groceries',\n",
       " 958: 'otherwise',\n",
       " 959: 'department',\n",
       " 960: 'urge',\n",
       " 961: 'continue',\n",
       " 962: 'selling',\n",
       " 963: 'product',\n",
       " 964: 'rewarded',\n",
       " 965: 'impersonal',\n",
       " 966: 'response',\n",
       " 967: 'written',\n",
       " 968: 'read',\n",
       " 969: 'letter',\n",
       " 970: 'ntoday',\n",
       " 971: 'usual',\n",
       " 972: 'noticed',\n",
       " 973: 'display',\n",
       " 974: 'longer',\n",
       " 975: 'immediately',\n",
       " 976: 'clear',\n",
       " 977: 'buying',\n",
       " 978: 'arrival',\n",
       " 979: 'purpose',\n",
       " 980: 'insulting',\n",
       " 981: 'continued',\n",
       " 982: 'full',\n",
       " 983: 'price',\n",
       " 984: 'compare',\n",
       " 985: 'shipped',\n",
       " 986: 'thailand',\n",
       " 987: 'miles',\n",
       " 988: 'road',\n",
       " 989: 'promptly',\n",
       " 990: 'wonder',\n",
       " 991: 'expects',\n",
       " 992: 'sitting',\n",
       " 993: 'freezer',\n",
       " 994: 'displayed',\n",
       " 995: 'nagain',\n",
       " 996: 'realize',\n",
       " 997: 'aren',\n",
       " 998: 'may',\n",
       " 999: 'worried',\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['i_2_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is the length of the vocab\n",
    "def one_hot_vector(token, N):\n",
    "    one_hot = np.zeros((N,1))\n",
    "    one_hot[look_up_token(token)] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "N = len(vocab['t_2_i'])\n",
    "print(one_hot_vector('worried', N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(doc,N):\n",
    "    is_first = True\n",
    "    for token in doc:\n",
    "        one_hot = one_hot_vector(token,N)\n",
    "        if is_first:\n",
    "            xF = one_hot\n",
    "            is_first = False\n",
    "        else:\n",
    "            xF = np.hstack((xF,one_hot))\n",
    "    return np.mean(xF,axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features_fast(doc,N):\n",
    "    feature_vector = np.zeros(N)\n",
    "    num_tokens = 0\n",
    "    for token in doc:\n",
    "        feature_vector[look_up_token(token)] += 1\n",
    "        num_tokens += 1\n",
    "    return feature_vector/num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_feature_matrix(Corpus,N):\n",
    "    is_first = True\n",
    "    for doc in Corpus:\n",
    "        feature_vector = compute_features(doc,N)\n",
    "        if is_first:\n",
    "            feature_matrix = feature_vector\n",
    "            is_first = False\n",
    "        else:\n",
    "            feature_matrix = np.hstack((feature_matric,feature_vector))\n",
    "    return feature_matrix.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_feature_matrix_fast(Corpus,N):\n",
    "    feature_matrix = np.zeros((N,len(Corpus)))\n",
    "    i = 0\n",
    "    for doc in Corpus:\n",
    "        feature_matrix[:,i] = compute_features_fast(doc,N)\n",
    "        i += 1\n",
    "    return feature_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = compute_features(Corpus[0],N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8946, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>terrible place to work for i just heard a stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>hours , minutes total time for an extremely s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my less than stellar review is for service . w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i m granting one star because there s no way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>the food here is mediocre at best . i went aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55995</th>\n",
       "      <td>positive</td>\n",
       "      <td>great food . wonderful , friendly service . i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>positive</td>\n",
       "      <td>charlotte should be the new standard for moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>positive</td>\n",
       "      <td>get the encore sandwich ! ! make sure to get i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>positive</td>\n",
       "      <td>i m a pretty big ice cream gelato fan . pretty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>positive</td>\n",
       "      <td>where else can you find all the parts and piec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating                                             review\n",
       "0      negative  terrible place to work for i just heard a stor...\n",
       "1      negative   hours , minutes total time for an extremely s...\n",
       "2      negative  my less than stellar review is for service . w...\n",
       "3      negative  i m granting one star because there s no way t...\n",
       "4      negative  the food here is mediocre at best . i went aft...\n",
       "...         ...                                                ...\n",
       "55995  positive  great food . wonderful , friendly service . i ...\n",
       "55996  positive  charlotte should be the new standard for moder...\n",
       "55997  positive  get the encore sandwich ! ! make sure to get i...\n",
       "55998  positive  i m a pretty big ice cream gelato fan . pretty...\n",
       "55999  positive  where else can you find all the parts and piec...\n",
       "\n",
       "[56000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df['review'])\n",
    "y = np.asarray(df['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_from_corpus(X_train)\n",
    "N = len(vocab['i_2_t'])\n",
    "X_train_feature_matrix = corpus_to_feature_matrix_fast(X_train,N)\n",
    "X_test_feature_matrix = corpus_to_feature_matrix_fast(X_test,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feature_matrix.shape , X_test_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X_train_feature_matrix,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = confusion_matrix(y_test,y_preds)\n",
    "sns.heatmap(plot.T,square = True,annot = True,fmt='d',cbar=False,xticklabels=np.unique(y),yticklabels=np.unique(y))\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
